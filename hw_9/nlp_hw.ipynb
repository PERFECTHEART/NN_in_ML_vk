{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-05-15T10:53:21.735772Z",
     "iopub.status.busy": "2023-05-15T10:53:21.735315Z",
     "iopub.status.idle": "2023-05-15T10:53:23.827518Z",
     "shell.execute_reply": "2023-05-15T10:53:23.826275Z",
     "shell.execute_reply.started": "2023-05-15T10:53:21.735720Z"
    },
    "id": "5HmwpqzwnMyE",
    "outputId": "357e52b5-5f6d-4263-f774-4dcbdb0adad9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'character-tokenizer'...\n",
      "remote: Enumerating objects: 16, done.\u001b[K\n",
      "remote: Counting objects: 100% (16/16), done.\u001b[K\n",
      "remote: Compressing objects: 100% (10/10), done.\u001b[K\n",
      "remote: Total 16 (delta 3), reused 12 (delta 3), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (16/16), 5.11 KiB | 653.00 KiB/s, done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/dariush-bahrami/character-tokenizer.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-15T10:53:23.834268Z",
     "iopub.status.busy": "2023-05-15T10:53:23.832359Z",
     "iopub.status.idle": "2023-05-15T10:53:36.088185Z",
     "shell.execute_reply": "2023-05-15T10:53:36.087026Z",
     "shell.execute_reply.started": "2023-05-15T10:53:23.834225Z"
    },
    "id": "hkVexA2nnRQ5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.28.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.11.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.3.23)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.4)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.28.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    " !pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-15T10:53:36.090703Z",
     "iopub.status.busy": "2023-05-15T10:53:36.090342Z",
     "iopub.status.idle": "2023-05-15T10:53:37.328933Z",
     "shell.execute_reply": "2023-05-15T10:53:37.328040Z",
     "shell.execute_reply.started": "2023-05-15T10:53:36.090666Z"
    },
    "id": "5FaCG9ajnS_G"
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import sys\n",
    "sys.path.append(\"/kaggle/working/character-tokenizer\")\n",
    "from charactertokenizer import CharacterTokenizer\n",
    "\n",
    "chars = \"АаБбВвГгДдЕеЁёЖжЗзИиЙйКкЛлМмНнОоПпРрСсТтУуФфХхЦцЧчШшЩщЪъЫыЬьЭэЮюЯя\"\n",
    "model_max_length = 64\n",
    "tokenizer = CharacterTokenizer(chars, model_max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-05-15T10:53:37.331942Z",
     "iopub.status.busy": "2023-05-15T10:53:37.331337Z",
     "iopub.status.idle": "2023-05-15T10:53:37.338812Z",
     "shell.execute_reply": "2023-05-15T10:53:37.337748Z",
     "shell.execute_reply.started": "2023-05-15T10:53:37.331906Z"
    },
    "id": "I5FSPMOSncpI",
    "outputId": "298569ea-c34c-46f4-acdd-d31ff08e7943"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [0, 39, 42, 26, 12, 18, 46, 1], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "example = \"Привет\"\n",
    "tokens = tokenizer(example)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-05-15T10:53:37.341582Z",
     "iopub.status.busy": "2023-05-15T10:53:37.340591Z",
     "iopub.status.idle": "2023-05-15T10:53:37.349673Z",
     "shell.execute_reply": "2023-05-15T10:53:37.348522Z",
     "shell.execute_reply.started": "2023-05-15T10:53:37.341548Z"
    },
    "id": "AioDA4WOMV66",
    "outputId": "d6a8dff6-6afd-4278-e80c-2f3c091226a3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]', 'П', 'р', 'и', 'в', 'е', 'т', '[SEP]']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(tokens['input_ids'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KQkp36rEoScR"
   },
   "source": [
    "Задание: обучите модель классификации букв для задачи расстановки ударения с помощью методов из библиотеки transformers. Датасет для обучения можно взять отсюда: https://github.com/Koziev/NLP_Datasets/blob/master/Stress/all_accents.zip\n",
    "\n",
    "1. Напишите класс для Dataset/Dataloder и азбейте данные на случайные train / test сплиты в соотношении 50:50. (1 балл)\n",
    "2. Попробуйте несколько моделей: Bert, Albert, Deberta. (3 балла)\n",
    "Пример конфигурации для deberta: https://huggingface.co/IlyaGusev/ru-word-stress-transformer/blob/main/config.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ФИО: Мушенко Егор Сергеевич"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-05-15T10:53:37.352087Z",
     "iopub.status.busy": "2023-05-15T10:53:37.351604Z",
     "iopub.status.idle": "2023-05-15T10:55:25.286398Z",
     "shell.execute_reply": "2023-05-15T10:55:25.285251Z",
     "shell.execute_reply.started": "2023-05-15T10:53:37.351957Z"
    },
    "id": "gdTKW8M3NEpD",
    "outputId": "4e8dfcf7-92ab-4174-fe3f-4766e571d1f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'NLP_Datasets'...\n",
      "remote: Enumerating objects: 595, done.\u001b[K\n",
      "remote: Counting objects: 100% (172/172), done.\u001b[K\n",
      "remote: Compressing objects: 100% (82/82), done.\u001b[K\n",
      "remote: Total 595 (delta 73), reused 166 (delta 67), pack-reused 423\u001b[K\n",
      "Receiving objects: 100% (595/595), 1.12 GiB | 19.02 MiB/s, done.\n",
      "Resolving deltas: 100% (253/253), done.\n",
      "Updating files: 100% (129/129), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/Koziev/NLP_Datasets.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-15T10:55:25.288793Z",
     "iopub.status.busy": "2023-05-15T10:55:25.288417Z",
     "iopub.status.idle": "2023-05-15T10:55:26.718413Z",
     "shell.execute_reply": "2023-05-15T10:55:26.717231Z",
     "shell.execute_reply.started": "2023-05-15T10:55:25.288751Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  NLP_Datasets/Stress/all_accents.zip\n",
      "  inflating: all_accents.tsv         \n"
     ]
    }
   ],
   "source": [
    "!unzip NLP_Datasets/Stress/all_accents.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-05-15T10:55:26.721929Z",
     "iopub.status.busy": "2023-05-15T10:55:26.721515Z",
     "iopub.status.idle": "2023-05-15T10:55:29.375712Z",
     "shell.execute_reply": "2023-05-15T10:55:29.374761Z",
     "shell.execute_reply.started": "2023-05-15T10:55:26.721883Z"
    },
    "id": "pPA_V4JqNEmx",
    "outputId": "4aa859af-355c-44e8-e80e-9d35a19e7d12"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1680534"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "device = 'cuda'\n",
    "df = pd.read_csv('all_accents.tsv', delimiter='\\t')\n",
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "execution": {
     "iopub.execute_input": "2023-05-15T10:55:29.377553Z",
     "iopub.status.busy": "2023-05-15T10:55:29.377219Z",
     "iopub.status.idle": "2023-05-15T10:55:30.454043Z",
     "shell.execute_reply": "2023-05-15T10:55:30.453037Z",
     "shell.execute_reply.started": "2023-05-15T10:55:29.377521Z"
    },
    "id": "cY9CfGjdngVw",
    "outputId": "99f590af-5d03-4901-b8cd-f06e0cc1b1fb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>-де</th>\n",
       "      <th>-д^е</th>\n",
       "      <th>target_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1040735</th>\n",
       "      <td>подзанялись</td>\n",
       "      <td>подзанял^ись</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12959</th>\n",
       "      <td>адвокатским</td>\n",
       "      <td>адвок^атским</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354236</th>\n",
       "      <td>дренаж</td>\n",
       "      <td>дрен^аж</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1628003</th>\n",
       "      <td>читалками</td>\n",
       "      <td>чит^алками</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900768</th>\n",
       "      <td>откатившею</td>\n",
       "      <td>откат^ившею</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1328016</th>\n",
       "      <td>рокируйте</td>\n",
       "      <td>рокир^уйте</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1400038</th>\n",
       "      <td>слякотный</td>\n",
       "      <td>сл^якотный</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1490237</th>\n",
       "      <td>типологии</td>\n",
       "      <td>типол^огии</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274344</th>\n",
       "      <td>разочаровывающему</td>\n",
       "      <td>разочар^овывающему</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942689</th>\n",
       "      <td>паломнической</td>\n",
       "      <td>пал^омнической</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       -де                -д^е  target_idx\n",
       "1040735        подзанялись        подзанял^ись           8\n",
       "12959          адвокатским        адвок^атским           5\n",
       "354236              дренаж             дрен^аж           4\n",
       "1628003          читалками          чит^алками           3\n",
       "900768          откатившею         откат^ившею           5\n",
       "1328016          рокируйте          рокир^уйте           5\n",
       "1400038          слякотный          сл^якотный           2\n",
       "1490237          типологии          типол^огии           5\n",
       "1274344  разочаровывающему  разочар^овывающему           7\n",
       "942689       паломнической      пал^омнической           3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target_idx'] = [word.find('^')for word in df['-д^е']]\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-05-15T10:55:30.458817Z",
     "iopub.status.busy": "2023-05-15T10:55:30.458494Z",
     "iopub.status.idle": "2023-05-15T10:55:30.610028Z",
     "shell.execute_reply": "2023-05-15T10:55:30.609015Z",
     "shell.execute_reply.started": "2023-05-15T10:55:30.458789Z"
    },
    "id": "g4qJFVFdnxaY",
    "outputId": "c60bcca8-8195-4754-8f89-9a45dcbc76c1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1680027"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(index=np.where(df.target_idx == -1)[0], inplace=True)\n",
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-15T10:55:30.611626Z",
     "iopub.status.busy": "2023-05-15T10:55:30.611275Z",
     "iopub.status.idle": "2023-05-15T10:55:30.619107Z",
     "shell.execute_reply": "2023-05-15T10:55:30.618167Z",
     "shell.execute_reply.started": "2023-05-15T10:55:30.611594Z"
    },
    "id": "MID6Scn_bFnQ"
   },
   "outputs": [],
   "source": [
    "train_words = df['-де']\n",
    "target = df.target_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-05-15T10:55:30.620724Z",
     "iopub.status.busy": "2023-05-15T10:55:30.620295Z",
     "iopub.status.idle": "2023-05-15T10:58:08.025386Z",
     "shell.execute_reply": "2023-05-15T10:58:08.024403Z",
     "shell.execute_reply.started": "2023-05-15T10:55:30.620683Z"
    },
    "id": "XSdd0vuuPuQ3",
    "outputId": "be04937c-fbf1-41e4-b7d5-1086baa1da6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max word length:  58\n"
     ]
    }
   ],
   "source": [
    "max_len = 0\n",
    "for word in train_words:\n",
    "    input_ids = tokenizer(word)['input_ids']\n",
    "    max_len = max(max_len, len(input_ids))\n",
    "print('Max word length: ', max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-15T10:58:08.028625Z",
     "iopub.status.busy": "2023-05-15T10:58:08.026705Z",
     "iopub.status.idle": "2023-05-15T11:05:42.858979Z",
     "shell.execute_reply": "2023-05-15T11:05:42.858034Z",
     "shell.execute_reply.started": "2023-05-15T10:58:08.028589Z"
    },
    "id": "eKx2esPocWfb"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e29634c7378e45f980c20cbf510ea3f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1680027 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "MAX_LENGTH = max_len\n",
    "# For every sentence...\n",
    "for word in tqdm(train_words):\n",
    "    encoded_dict = tokenizer(\n",
    "                        word,\n",
    "                        add_special_tokens = True,\n",
    "                        max_length = MAX_LENGTH,   \n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,\n",
    "                        return_tensors = 'pt',\n",
    "                   )\n",
    "    \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-05-15T11:05:42.860963Z",
     "iopub.status.busy": "2023-05-15T11:05:42.860108Z",
     "iopub.status.idle": "2023-05-15T11:05:52.000197Z",
     "shell.execute_reply": "2023-05-15T11:05:51.999089Z",
     "shell.execute_reply.started": "2023-05-15T11:05:42.860925Z"
    },
    "id": "IzEf3ITGsUH1",
    "outputId": "564a2fa9-40ad-459c-f84a-935774042eac"
   },
   "outputs": [],
   "source": [
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(target.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-05-15T11:05:52.002041Z",
     "iopub.status.busy": "2023-05-15T11:05:52.001680Z",
     "iopub.status.idle": "2023-05-15T11:05:52.044594Z",
     "shell.execute_reply": "2023-05-15T11:05:52.043825Z",
     "shell.execute_reply.started": "2023-05-15T11:05:52.001991Z"
    },
    "id": "KxnSkzSiszkr",
    "outputId": "7ece42be-f5b9-410d-d0f7-fece92e5f288"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  агарак\n",
      "Token IDs: tensor([ 0,  8, 14,  8, 42,  8, 30,  8, 12,  8, 36,  1,  4,  4,  4,  4,  4,  4,\n",
      "         4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
      "         4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
      "         4,  4,  4,  4])\n"
     ]
    }
   ],
   "source": [
    "i = 10000\n",
    "print('Original: ', train_words[i])\n",
    "print('Token IDs:', input_ids[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-05-15T11:05:52.048344Z",
     "iopub.status.busy": "2023-05-15T11:05:52.047841Z",
     "iopub.status.idle": "2023-05-15T11:05:52.056911Z",
     "shell.execute_reply": "2023-05-15T11:05:52.056072Z",
     "shell.execute_reply.started": "2023-05-15T11:05:52.048317Z"
    },
    "id": "TjjGQimsuPoO",
    "outputId": "5d613603-448e-46fe-9f24-d5749ef4e8c1"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, random_split\n",
    "\n",
    "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "max_len = 58"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-05-15T11:05:52.063251Z",
     "iopub.status.busy": "2023-05-15T11:05:52.060616Z",
     "iopub.status.idle": "2023-05-15T11:05:52.212289Z",
     "shell.execute_reply": "2023-05-15T11:05:52.211167Z",
     "shell.execute_reply.started": "2023-05-15T11:05:52.063219Z"
    },
    "id": "hZGqGipTcO4R",
    "outputId": "3c63591b-e2b9-41ce-8dea-b29aa6bd3ae5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "840,013 training samples\n",
      "840,014 validation samples\n"
     ]
    }
   ],
   "source": [
    "train_size = int(0.5 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "print('{:>5,} training samples'.format(train_size))\n",
    "print('{:>5,} validation samples'.format(val_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-15T11:05:52.216615Z",
     "iopub.status.busy": "2023-05-15T11:05:52.213646Z",
     "iopub.status.idle": "2023-05-15T11:05:52.221063Z",
     "shell.execute_reply": "2023-05-15T11:05:52.220079Z",
     "shell.execute_reply.started": "2023-05-15T11:05:52.216584Z"
    },
    "id": "rdYv_w3wtwW4"
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-15T11:05:52.223296Z",
     "iopub.status.busy": "2023-05-15T11:05:52.222879Z",
     "iopub.status.idle": "2023-05-15T11:05:52.231996Z",
     "shell.execute_reply": "2023-05-15T11:05:52.231055Z",
     "shell.execute_reply.started": "2023-05-15T11:05:52.223215Z"
    },
    "id": "iOiv0hMQcO02"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,  \n",
    "            sampler = RandomSampler(train_dataset), \n",
    "            batch_size = batch_size \n",
    "        )\n",
    "\n",
    "validation_dataloader = DataLoader(\n",
    "            val_dataset, \n",
    "            sampler = SequentialSampler(val_dataset),\n",
    "            batch_size = batch_size \n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-15T11:05:52.233820Z",
     "iopub.status.busy": "2023-05-15T11:05:52.233178Z",
     "iopub.status.idle": "2023-05-15T11:05:52.242585Z",
     "shell.execute_reply": "2023-05-15T11:05:52.241683Z",
     "shell.execute_reply.started": "2023-05-15T11:05:52.233787Z"
    },
    "id": "tsgwed4RcOql"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "def format_time(elapsed):\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
    "\n",
    "\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-15T11:05:52.244519Z",
     "iopub.status.busy": "2023-05-15T11:05:52.244161Z",
     "iopub.status.idle": "2023-05-15T11:05:52.274393Z",
     "shell.execute_reply": "2023-05-15T11:05:52.272260Z",
     "shell.execute_reply.started": "2023-05-15T11:05:52.244486Z"
    },
    "id": "q3F1KKP9esGe"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def train_model(model, optimizer, scheduler, epochs, val_step=True):\n",
    "    seed_val = 42\n",
    "    random.seed(seed_val)\n",
    "    np.random.seed(seed_val)\n",
    "    torch.manual_seed(seed_val)\n",
    "    torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "    training_stats = []\n",
    "\n",
    "    total_t0 = time.time()\n",
    "\n",
    "    for epoch_i in range(0, epochs):\n",
    "        t0 = time.time()\n",
    "        total_train_loss = 0\n",
    "        model.train()\n",
    "\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            if step % 100 == 0 and not step == 0:\n",
    "                elapsed = format_time(time.time() - t0)\n",
    "                print('  Batch {:>5,}  of  {:>5,}'.format(step, len(train_dataloader)))\n",
    "\n",
    "            b_input_ids = batch[0].to(device)\n",
    "            b_input_mask = batch[1].to(device)\n",
    "            b_labels = batch[2].to(device)\n",
    "\n",
    "            model.zero_grad()        \n",
    "\n",
    "            output = model(b_input_ids, token_type_ids=None,\n",
    "                          attention_mask=b_input_mask, labels=b_labels)\n",
    "\n",
    "            total_train_loss += output.loss.item()\n",
    "            output.loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(train_dataloader)            \n",
    "        training_time = format_time(time.time() - t0)\n",
    "        print(\"\\n  Avg loss: {0:.2f}\".format(avg_train_loss))\n",
    "            \n",
    "        # val\n",
    "        if not val_step:\n",
    "            continue\n",
    "\n",
    "        t0 = time.time()\n",
    "        model.eval()\n",
    "\n",
    "        total_eval_accuracy = 0\n",
    "        total_eval_loss = 0\n",
    "        nb_eval_steps = 0\n",
    "\n",
    "        for batch in validation_dataloader:\n",
    "            b_input_ids = batch[0].to(device)\n",
    "            b_input_mask = batch[1].to(device)\n",
    "            b_labels = batch[2].to(device)\n",
    "            \n",
    "            with torch.no_grad():        \n",
    "                output = model(b_input_ids, token_type_ids=None, \n",
    "                              attention_mask=b_input_mask, labels=b_labels)\n",
    "                \n",
    "            total_eval_loss += output.loss.item()\n",
    "\n",
    "            logits = output.logits.detach().cpu().numpy()\n",
    "            label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "            total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "            \n",
    "\n",
    "        avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "        print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "\n",
    "        avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "        validation_time = format_time(time.time() - t0)       \n",
    "        print(\"  Avg validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "        print(\"  Total validation time: {:}\\n\".format(validation_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-15T11:05:52.276679Z",
     "iopub.status.busy": "2023-05-15T11:05:52.276053Z",
     "iopub.status.idle": "2023-05-15T11:05:52.287110Z",
     "shell.execute_reply": "2023-05-15T11:05:52.286147Z",
     "shell.execute_reply.started": "2023-05-15T11:05:52.276646Z"
    },
    "id": "G_g2LOK3esB6"
   },
   "outputs": [],
   "source": [
    "def test_model(model):\n",
    "    model.eval()\n",
    "    samples = df.sample(10)\n",
    "    pred = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(10):\n",
    "            word = samples.iloc[i]['-де']\n",
    "            input = torch.tensor(tokenizer(word)['input_ids']).to(device)\n",
    "            output = model(input.unsqueeze(0))\n",
    "            preds = output.logits.detach().cpu().numpy()\n",
    "            ans = np.argmax(preds, axis=1)[0]\n",
    "            pred.append(word[:ans] + '^' + word[ans:])\n",
    "    samples['prediction'] = pred\n",
    "    samples['is_right'] = [int(inp == out) for inp, out in zip(samples['-д^е'], pred)]\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d_Q_Rf2rjRxU"
   },
   "source": [
    "### BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 188,
     "referenced_widgets": [
      "419b97e53a9842f7ae242e4249dc3797",
      "0ee608c218b649a7916fbee284760539",
      "2df73a2904544963a11c1fad9f813740",
      "b94c3bfc73564bb98dc424718cec3a58",
      "f1a37e256c084e0e80afba84994fd1a7",
      "358569e5d3b94e3fb4522a0a35b6084e",
      "2cc58540b2754481b3ac83c137c2ba29",
      "a67a910967024ee7a4eca678696b34c5",
      "43542f8f319c4812b56318ed3e71dbed",
      "bd3c10661cfe4253a7df491f05d2335a",
      "c7a0e6aa4f9b4f898ea2bfdb581e19b2",
      "efaad66443e642b8a781d2a7bdad8220",
      "3e203b1662e64492a2057d4520fa0368",
      "ae85c3386d5d41b1afe0efc511ff94ef",
      "a1f4179ff58042e4bed123c98884ac0d",
      "950d893c4a4e4311a5b1a20aa05b2b60",
      "407368c5a9a746acad253726bd58809a",
      "a31387adc7904ba28185a0fe8c1a78f1",
      "08ea5244434a483696ec055f4df09b54",
      "dc60e7c734c1439caea37c4eaeb81f99",
      "b209c059ebdc4f2495392515d3645f46",
      "7e30d332ebaf4ef7a5c425a859680239"
     ]
    },
    "execution": {
     "iopub.execute_input": "2023-05-15T11:05:52.289407Z",
     "iopub.status.busy": "2023-05-15T11:05:52.288321Z",
     "iopub.status.idle": "2023-05-15T11:06:09.702195Z",
     "shell.execute_reply": "2023-05-15T11:06:09.701199Z",
     "shell.execute_reply.started": "2023-05-15T11:05:52.289375Z"
    },
    "id": "DBBP-Hd2cOxb",
    "outputId": "46feb152-84a5-4742-c333-c0f7cdccfb25"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3d8322783d148059f8132a082f0f464",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/632 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "774dae14eadc4a20a527f9abe4528031",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/47.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cointegrated/rubert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cointegrated/rubert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"cointegrated/rubert-tiny\", \n",
    "    num_labels = max_len - 1,   \n",
    "    output_attentions = False, \n",
    "    output_hidden_states = False, \n",
    ")\n",
    "\n",
    "model.to(device)\n",
    "optimizer = AdamW(model.parameters(),lr = 2e-5, eps = 1e-8)\n",
    "\n",
    "epochs = 4\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0,\n",
    "                                            num_training_steps = total_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-05-15T11:06:09.704283Z",
     "iopub.status.busy": "2023-05-15T11:06:09.703630Z",
     "iopub.status.idle": "2023-05-15T11:34:43.324505Z",
     "shell.execute_reply": "2023-05-15T11:34:43.323498Z",
     "shell.execute_reply.started": "2023-05-15T11:06:09.704248Z"
    },
    "id": "zX2hY5T-esEE",
    "outputId": "0dd671c2-6b9b-4970-8b5f-5bded7bc5190"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   100  of  13,126\n",
      "  Batch   200  of  13,126\n",
      "  Batch   300  of  13,126\n",
      "  Batch   400  of  13,126\n",
      "  Batch   500  of  13,126\n",
      "  Batch   600  of  13,126\n",
      "  Batch   700  of  13,126\n",
      "  Batch   800  of  13,126\n",
      "  Batch   900  of  13,126\n",
      "  Batch 1,000  of  13,126\n",
      "  Batch 1,100  of  13,126\n",
      "  Batch 1,200  of  13,126\n",
      "  Batch 1,300  of  13,126\n",
      "  Batch 1,400  of  13,126\n",
      "  Batch 1,500  of  13,126\n",
      "  Batch 1,600  of  13,126\n",
      "  Batch 1,700  of  13,126\n",
      "  Batch 1,800  of  13,126\n",
      "  Batch 1,900  of  13,126\n",
      "  Batch 2,000  of  13,126\n",
      "  Batch 2,100  of  13,126\n",
      "  Batch 2,200  of  13,126\n",
      "  Batch 2,300  of  13,126\n",
      "  Batch 2,400  of  13,126\n",
      "  Batch 2,500  of  13,126\n",
      "  Batch 2,600  of  13,126\n",
      "  Batch 2,700  of  13,126\n",
      "  Batch 2,800  of  13,126\n",
      "  Batch 2,900  of  13,126\n",
      "  Batch 3,000  of  13,126\n",
      "  Batch 3,100  of  13,126\n",
      "  Batch 3,200  of  13,126\n",
      "  Batch 3,300  of  13,126\n",
      "  Batch 3,400  of  13,126\n",
      "  Batch 3,500  of  13,126\n",
      "  Batch 3,600  of  13,126\n",
      "  Batch 3,700  of  13,126\n",
      "  Batch 3,800  of  13,126\n",
      "  Batch 3,900  of  13,126\n",
      "  Batch 4,000  of  13,126\n",
      "  Batch 4,100  of  13,126\n",
      "  Batch 4,200  of  13,126\n",
      "  Batch 4,300  of  13,126\n",
      "  Batch 4,400  of  13,126\n",
      "  Batch 4,500  of  13,126\n",
      "  Batch 4,600  of  13,126\n",
      "  Batch 4,700  of  13,126\n",
      "  Batch 4,800  of  13,126\n",
      "  Batch 4,900  of  13,126\n",
      "  Batch 5,000  of  13,126\n",
      "  Batch 5,100  of  13,126\n",
      "  Batch 5,200  of  13,126\n",
      "  Batch 5,300  of  13,126\n",
      "  Batch 5,400  of  13,126\n",
      "  Batch 5,500  of  13,126\n",
      "  Batch 5,600  of  13,126\n",
      "  Batch 5,700  of  13,126\n",
      "  Batch 5,800  of  13,126\n",
      "  Batch 5,900  of  13,126\n",
      "  Batch 6,000  of  13,126\n",
      "  Batch 6,100  of  13,126\n",
      "  Batch 6,200  of  13,126\n",
      "  Batch 6,300  of  13,126\n",
      "  Batch 6,400  of  13,126\n",
      "  Batch 6,500  of  13,126\n",
      "  Batch 6,600  of  13,126\n",
      "  Batch 6,700  of  13,126\n",
      "  Batch 6,800  of  13,126\n",
      "  Batch 6,900  of  13,126\n",
      "  Batch 7,000  of  13,126\n",
      "  Batch 7,100  of  13,126\n",
      "  Batch 7,200  of  13,126\n",
      "  Batch 7,300  of  13,126\n",
      "  Batch 7,400  of  13,126\n",
      "  Batch 7,500  of  13,126\n",
      "  Batch 7,600  of  13,126\n",
      "  Batch 7,700  of  13,126\n",
      "  Batch 7,800  of  13,126\n",
      "  Batch 7,900  of  13,126\n",
      "  Batch 8,000  of  13,126\n",
      "  Batch 8,100  of  13,126\n",
      "  Batch 8,200  of  13,126\n",
      "  Batch 8,300  of  13,126\n",
      "  Batch 8,400  of  13,126\n",
      "  Batch 8,500  of  13,126\n",
      "  Batch 8,600  of  13,126\n",
      "  Batch 8,700  of  13,126\n",
      "  Batch 8,800  of  13,126\n",
      "  Batch 8,900  of  13,126\n",
      "  Batch 9,000  of  13,126\n",
      "  Batch 9,100  of  13,126\n",
      "  Batch 9,200  of  13,126\n",
      "  Batch 9,300  of  13,126\n",
      "  Batch 9,400  of  13,126\n",
      "  Batch 9,500  of  13,126\n",
      "  Batch 9,600  of  13,126\n",
      "  Batch 9,700  of  13,126\n",
      "  Batch 9,800  of  13,126\n",
      "  Batch 9,900  of  13,126\n",
      "  Batch 10,000  of  13,126\n",
      "  Batch 10,100  of  13,126\n",
      "  Batch 10,200  of  13,126\n",
      "  Batch 10,300  of  13,126\n",
      "  Batch 10,400  of  13,126\n",
      "  Batch 10,500  of  13,126\n",
      "  Batch 10,600  of  13,126\n",
      "  Batch 10,700  of  13,126\n",
      "  Batch 10,800  of  13,126\n",
      "  Batch 10,900  of  13,126\n",
      "  Batch 11,000  of  13,126\n",
      "  Batch 11,100  of  13,126\n",
      "  Batch 11,200  of  13,126\n",
      "  Batch 11,300  of  13,126\n",
      "  Batch 11,400  of  13,126\n",
      "  Batch 11,500  of  13,126\n",
      "  Batch 11,600  of  13,126\n",
      "  Batch 11,700  of  13,126\n",
      "  Batch 11,800  of  13,126\n",
      "  Batch 11,900  of  13,126\n",
      "  Batch 12,000  of  13,126\n",
      "  Batch 12,100  of  13,126\n",
      "  Batch 12,200  of  13,126\n",
      "  Batch 12,300  of  13,126\n",
      "  Batch 12,400  of  13,126\n",
      "  Batch 12,500  of  13,126\n",
      "  Batch 12,600  of  13,126\n",
      "  Batch 12,700  of  13,126\n",
      "  Batch 12,800  of  13,126\n",
      "  Batch 12,900  of  13,126\n",
      "  Batch 13,000  of  13,126\n",
      "  Batch 13,100  of  13,126\n",
      "\n",
      "  Avg loss: 1.16\n",
      "  Accuracy: 0.77\n",
      "  Avg validation Loss: 0.64\n",
      "  Total validation time: 0:01:36\n",
      "\n",
      "  Batch   100  of  13,126\n",
      "  Batch   200  of  13,126\n",
      "  Batch   300  of  13,126\n",
      "  Batch   400  of  13,126\n",
      "  Batch   500  of  13,126\n",
      "  Batch   600  of  13,126\n",
      "  Batch   700  of  13,126\n",
      "  Batch   800  of  13,126\n",
      "  Batch   900  of  13,126\n",
      "  Batch 1,000  of  13,126\n",
      "  Batch 1,100  of  13,126\n",
      "  Batch 1,200  of  13,126\n",
      "  Batch 1,300  of  13,126\n",
      "  Batch 1,400  of  13,126\n",
      "  Batch 1,500  of  13,126\n",
      "  Batch 1,600  of  13,126\n",
      "  Batch 1,700  of  13,126\n",
      "  Batch 1,800  of  13,126\n",
      "  Batch 1,900  of  13,126\n",
      "  Batch 2,000  of  13,126\n",
      "  Batch 2,100  of  13,126\n",
      "  Batch 2,200  of  13,126\n",
      "  Batch 2,300  of  13,126\n",
      "  Batch 2,400  of  13,126\n",
      "  Batch 2,500  of  13,126\n",
      "  Batch 2,600  of  13,126\n",
      "  Batch 2,700  of  13,126\n",
      "  Batch 2,800  of  13,126\n",
      "  Batch 2,900  of  13,126\n",
      "  Batch 3,000  of  13,126\n",
      "  Batch 3,100  of  13,126\n",
      "  Batch 3,200  of  13,126\n",
      "  Batch 3,300  of  13,126\n",
      "  Batch 3,400  of  13,126\n",
      "  Batch 3,500  of  13,126\n",
      "  Batch 3,600  of  13,126\n",
      "  Batch 3,700  of  13,126\n",
      "  Batch 3,800  of  13,126\n",
      "  Batch 3,900  of  13,126\n",
      "  Batch 4,000  of  13,126\n",
      "  Batch 4,100  of  13,126\n",
      "  Batch 4,200  of  13,126\n",
      "  Batch 4,300  of  13,126\n",
      "  Batch 4,400  of  13,126\n",
      "  Batch 4,500  of  13,126\n",
      "  Batch 4,600  of  13,126\n",
      "  Batch 4,700  of  13,126\n",
      "  Batch 4,800  of  13,126\n",
      "  Batch 4,900  of  13,126\n",
      "  Batch 5,000  of  13,126\n",
      "  Batch 5,100  of  13,126\n",
      "  Batch 5,200  of  13,126\n",
      "  Batch 5,300  of  13,126\n",
      "  Batch 5,400  of  13,126\n",
      "  Batch 5,500  of  13,126\n",
      "  Batch 5,600  of  13,126\n",
      "  Batch 5,700  of  13,126\n",
      "  Batch 5,800  of  13,126\n",
      "  Batch 5,900  of  13,126\n",
      "  Batch 6,000  of  13,126\n",
      "  Batch 6,100  of  13,126\n",
      "  Batch 6,200  of  13,126\n",
      "  Batch 6,300  of  13,126\n",
      "  Batch 6,400  of  13,126\n",
      "  Batch 6,500  of  13,126\n",
      "  Batch 6,600  of  13,126\n",
      "  Batch 6,700  of  13,126\n",
      "  Batch 6,800  of  13,126\n",
      "  Batch 6,900  of  13,126\n",
      "  Batch 7,000  of  13,126\n",
      "  Batch 7,100  of  13,126\n",
      "  Batch 7,200  of  13,126\n",
      "  Batch 7,300  of  13,126\n",
      "  Batch 7,400  of  13,126\n",
      "  Batch 7,500  of  13,126\n",
      "  Batch 7,600  of  13,126\n",
      "  Batch 7,700  of  13,126\n",
      "  Batch 7,800  of  13,126\n",
      "  Batch 7,900  of  13,126\n",
      "  Batch 8,000  of  13,126\n",
      "  Batch 8,100  of  13,126\n",
      "  Batch 8,200  of  13,126\n",
      "  Batch 8,300  of  13,126\n",
      "  Batch 8,400  of  13,126\n",
      "  Batch 8,500  of  13,126\n",
      "  Batch 8,600  of  13,126\n",
      "  Batch 8,700  of  13,126\n",
      "  Batch 8,800  of  13,126\n",
      "  Batch 8,900  of  13,126\n",
      "  Batch 9,000  of  13,126\n",
      "  Batch 9,100  of  13,126\n",
      "  Batch 9,200  of  13,126\n",
      "  Batch 9,300  of  13,126\n",
      "  Batch 9,400  of  13,126\n",
      "  Batch 9,500  of  13,126\n",
      "  Batch 9,600  of  13,126\n",
      "  Batch 9,700  of  13,126\n",
      "  Batch 9,800  of  13,126\n",
      "  Batch 9,900  of  13,126\n",
      "  Batch 10,000  of  13,126\n",
      "  Batch 10,100  of  13,126\n",
      "  Batch 10,200  of  13,126\n",
      "  Batch 10,300  of  13,126\n",
      "  Batch 10,400  of  13,126\n",
      "  Batch 10,500  of  13,126\n",
      "  Batch 10,600  of  13,126\n",
      "  Batch 10,700  of  13,126\n",
      "  Batch 10,800  of  13,126\n",
      "  Batch 10,900  of  13,126\n",
      "  Batch 11,000  of  13,126\n",
      "  Batch 11,100  of  13,126\n",
      "  Batch 11,200  of  13,126\n",
      "  Batch 11,300  of  13,126\n",
      "  Batch 11,400  of  13,126\n",
      "  Batch 11,500  of  13,126\n",
      "  Batch 11,600  of  13,126\n",
      "  Batch 11,700  of  13,126\n",
      "  Batch 11,800  of  13,126\n",
      "  Batch 11,900  of  13,126\n",
      "  Batch 12,000  of  13,126\n",
      "  Batch 12,100  of  13,126\n",
      "  Batch 12,200  of  13,126\n",
      "  Batch 12,300  of  13,126\n",
      "  Batch 12,400  of  13,126\n",
      "  Batch 12,500  of  13,126\n",
      "  Batch 12,600  of  13,126\n",
      "  Batch 12,700  of  13,126\n",
      "  Batch 12,800  of  13,126\n",
      "  Batch 12,900  of  13,126\n",
      "  Batch 13,000  of  13,126\n",
      "  Batch 13,100  of  13,126\n",
      "\n",
      "  Avg loss: 0.64\n",
      "  Accuracy: 0.80\n",
      "  Avg validation Loss: 0.52\n",
      "  Total validation time: 0:01:36\n",
      "\n",
      "  Batch   100  of  13,126\n",
      "  Batch   200  of  13,126\n",
      "  Batch   300  of  13,126\n",
      "  Batch   400  of  13,126\n",
      "  Batch   500  of  13,126\n",
      "  Batch   600  of  13,126\n",
      "  Batch   700  of  13,126\n",
      "  Batch   800  of  13,126\n",
      "  Batch   900  of  13,126\n",
      "  Batch 1,000  of  13,126\n",
      "  Batch 1,100  of  13,126\n",
      "  Batch 1,200  of  13,126\n",
      "  Batch 1,300  of  13,126\n",
      "  Batch 1,400  of  13,126\n",
      "  Batch 1,500  of  13,126\n",
      "  Batch 1,600  of  13,126\n",
      "  Batch 1,700  of  13,126\n",
      "  Batch 1,800  of  13,126\n",
      "  Batch 1,900  of  13,126\n",
      "  Batch 2,000  of  13,126\n",
      "  Batch 2,100  of  13,126\n",
      "  Batch 2,200  of  13,126\n",
      "  Batch 2,300  of  13,126\n",
      "  Batch 2,400  of  13,126\n",
      "  Batch 2,500  of  13,126\n",
      "  Batch 2,600  of  13,126\n",
      "  Batch 2,700  of  13,126\n",
      "  Batch 2,800  of  13,126\n",
      "  Batch 2,900  of  13,126\n",
      "  Batch 3,000  of  13,126\n",
      "  Batch 3,100  of  13,126\n",
      "  Batch 3,200  of  13,126\n",
      "  Batch 3,300  of  13,126\n",
      "  Batch 3,400  of  13,126\n",
      "  Batch 3,500  of  13,126\n",
      "  Batch 3,600  of  13,126\n",
      "  Batch 3,700  of  13,126\n",
      "  Batch 3,800  of  13,126\n",
      "  Batch 3,900  of  13,126\n",
      "  Batch 4,000  of  13,126\n",
      "  Batch 4,100  of  13,126\n",
      "  Batch 4,200  of  13,126\n",
      "  Batch 4,300  of  13,126\n",
      "  Batch 4,400  of  13,126\n",
      "  Batch 4,500  of  13,126\n",
      "  Batch 4,600  of  13,126\n",
      "  Batch 4,700  of  13,126\n",
      "  Batch 4,800  of  13,126\n",
      "  Batch 4,900  of  13,126\n",
      "  Batch 5,000  of  13,126\n",
      "  Batch 5,100  of  13,126\n",
      "  Batch 5,200  of  13,126\n",
      "  Batch 5,300  of  13,126\n",
      "  Batch 5,400  of  13,126\n",
      "  Batch 5,500  of  13,126\n",
      "  Batch 5,600  of  13,126\n",
      "  Batch 5,700  of  13,126\n",
      "  Batch 5,800  of  13,126\n",
      "  Batch 5,900  of  13,126\n",
      "  Batch 6,000  of  13,126\n",
      "  Batch 6,100  of  13,126\n",
      "  Batch 6,200  of  13,126\n",
      "  Batch 6,300  of  13,126\n",
      "  Batch 6,400  of  13,126\n",
      "  Batch 6,500  of  13,126\n",
      "  Batch 6,600  of  13,126\n",
      "  Batch 6,700  of  13,126\n",
      "  Batch 6,800  of  13,126\n",
      "  Batch 6,900  of  13,126\n",
      "  Batch 7,000  of  13,126\n",
      "  Batch 7,100  of  13,126\n",
      "  Batch 7,200  of  13,126\n",
      "  Batch 7,300  of  13,126\n",
      "  Batch 7,400  of  13,126\n",
      "  Batch 7,500  of  13,126\n",
      "  Batch 7,600  of  13,126\n",
      "  Batch 7,700  of  13,126\n",
      "  Batch 7,800  of  13,126\n",
      "  Batch 7,900  of  13,126\n",
      "  Batch 8,000  of  13,126\n",
      "  Batch 8,100  of  13,126\n",
      "  Batch 8,200  of  13,126\n",
      "  Batch 8,300  of  13,126\n",
      "  Batch 8,400  of  13,126\n",
      "  Batch 8,500  of  13,126\n",
      "  Batch 8,600  of  13,126\n",
      "  Batch 8,700  of  13,126\n",
      "  Batch 8,800  of  13,126\n",
      "  Batch 8,900  of  13,126\n",
      "  Batch 9,000  of  13,126\n",
      "  Batch 9,100  of  13,126\n",
      "  Batch 9,200  of  13,126\n",
      "  Batch 9,300  of  13,126\n",
      "  Batch 9,400  of  13,126\n",
      "  Batch 9,500  of  13,126\n",
      "  Batch 9,600  of  13,126\n",
      "  Batch 9,700  of  13,126\n",
      "  Batch 9,800  of  13,126\n",
      "  Batch 9,900  of  13,126\n",
      "  Batch 10,000  of  13,126\n",
      "  Batch 10,100  of  13,126\n",
      "  Batch 10,200  of  13,126\n",
      "  Batch 10,300  of  13,126\n",
      "  Batch 10,400  of  13,126\n",
      "  Batch 10,500  of  13,126\n",
      "  Batch 10,600  of  13,126\n",
      "  Batch 10,700  of  13,126\n",
      "  Batch 10,800  of  13,126\n",
      "  Batch 10,900  of  13,126\n",
      "  Batch 11,000  of  13,126\n",
      "  Batch 11,100  of  13,126\n",
      "  Batch 11,200  of  13,126\n",
      "  Batch 11,300  of  13,126\n",
      "  Batch 11,400  of  13,126\n",
      "  Batch 11,500  of  13,126\n",
      "  Batch 11,600  of  13,126\n",
      "  Batch 11,700  of  13,126\n",
      "  Batch 11,800  of  13,126\n",
      "  Batch 11,900  of  13,126\n",
      "  Batch 12,000  of  13,126\n",
      "  Batch 12,100  of  13,126\n",
      "  Batch 12,200  of  13,126\n",
      "  Batch 12,300  of  13,126\n",
      "  Batch 12,400  of  13,126\n",
      "  Batch 12,500  of  13,126\n",
      "  Batch 12,600  of  13,126\n",
      "  Batch 12,700  of  13,126\n",
      "  Batch 12,800  of  13,126\n",
      "  Batch 12,900  of  13,126\n",
      "  Batch 13,000  of  13,126\n",
      "  Batch 13,100  of  13,126\n",
      "\n",
      "  Avg loss: 0.56\n",
      "  Accuracy: 0.82\n",
      "  Avg validation Loss: 0.48\n",
      "  Total validation time: 0:01:36\n",
      "\n",
      "  Batch   100  of  13,126\n",
      "  Batch   200  of  13,126\n",
      "  Batch   300  of  13,126\n",
      "  Batch   400  of  13,126\n",
      "  Batch   500  of  13,126\n",
      "  Batch   600  of  13,126\n",
      "  Batch   700  of  13,126\n",
      "  Batch   800  of  13,126\n",
      "  Batch   900  of  13,126\n",
      "  Batch 1,000  of  13,126\n",
      "  Batch 1,100  of  13,126\n",
      "  Batch 1,200  of  13,126\n",
      "  Batch 1,300  of  13,126\n",
      "  Batch 1,400  of  13,126\n",
      "  Batch 1,500  of  13,126\n",
      "  Batch 1,600  of  13,126\n",
      "  Batch 1,700  of  13,126\n",
      "  Batch 1,800  of  13,126\n",
      "  Batch 1,900  of  13,126\n",
      "  Batch 2,000  of  13,126\n",
      "  Batch 2,100  of  13,126\n",
      "  Batch 2,200  of  13,126\n",
      "  Batch 2,300  of  13,126\n",
      "  Batch 2,400  of  13,126\n",
      "  Batch 2,500  of  13,126\n",
      "  Batch 2,600  of  13,126\n",
      "  Batch 2,700  of  13,126\n",
      "  Batch 2,800  of  13,126\n",
      "  Batch 2,900  of  13,126\n",
      "  Batch 3,000  of  13,126\n",
      "  Batch 3,100  of  13,126\n",
      "  Batch 3,200  of  13,126\n",
      "  Batch 3,300  of  13,126\n",
      "  Batch 3,400  of  13,126\n",
      "  Batch 3,500  of  13,126\n",
      "  Batch 3,600  of  13,126\n",
      "  Batch 3,700  of  13,126\n",
      "  Batch 3,800  of  13,126\n",
      "  Batch 3,900  of  13,126\n",
      "  Batch 4,000  of  13,126\n",
      "  Batch 4,100  of  13,126\n",
      "  Batch 4,200  of  13,126\n",
      "  Batch 4,300  of  13,126\n",
      "  Batch 4,400  of  13,126\n",
      "  Batch 4,500  of  13,126\n",
      "  Batch 4,600  of  13,126\n",
      "  Batch 4,700  of  13,126\n",
      "  Batch 4,800  of  13,126\n",
      "  Batch 4,900  of  13,126\n",
      "  Batch 5,000  of  13,126\n",
      "  Batch 5,100  of  13,126\n",
      "  Batch 5,200  of  13,126\n",
      "  Batch 5,300  of  13,126\n",
      "  Batch 5,400  of  13,126\n",
      "  Batch 5,500  of  13,126\n",
      "  Batch 5,600  of  13,126\n",
      "  Batch 5,700  of  13,126\n",
      "  Batch 5,800  of  13,126\n",
      "  Batch 5,900  of  13,126\n",
      "  Batch 6,000  of  13,126\n",
      "  Batch 6,100  of  13,126\n",
      "  Batch 6,200  of  13,126\n",
      "  Batch 6,300  of  13,126\n",
      "  Batch 6,400  of  13,126\n",
      "  Batch 6,500  of  13,126\n",
      "  Batch 6,600  of  13,126\n",
      "  Batch 6,700  of  13,126\n",
      "  Batch 6,800  of  13,126\n",
      "  Batch 6,900  of  13,126\n",
      "  Batch 7,000  of  13,126\n",
      "  Batch 7,100  of  13,126\n",
      "  Batch 7,200  of  13,126\n",
      "  Batch 7,300  of  13,126\n",
      "  Batch 7,400  of  13,126\n",
      "  Batch 7,500  of  13,126\n",
      "  Batch 7,600  of  13,126\n",
      "  Batch 7,700  of  13,126\n",
      "  Batch 7,800  of  13,126\n",
      "  Batch 7,900  of  13,126\n",
      "  Batch 8,000  of  13,126\n",
      "  Batch 8,100  of  13,126\n",
      "  Batch 8,200  of  13,126\n",
      "  Batch 8,300  of  13,126\n",
      "  Batch 8,400  of  13,126\n",
      "  Batch 8,500  of  13,126\n",
      "  Batch 8,600  of  13,126\n",
      "  Batch 8,700  of  13,126\n",
      "  Batch 8,800  of  13,126\n",
      "  Batch 8,900  of  13,126\n",
      "  Batch 9,000  of  13,126\n",
      "  Batch 9,100  of  13,126\n",
      "  Batch 9,200  of  13,126\n",
      "  Batch 9,300  of  13,126\n",
      "  Batch 9,400  of  13,126\n",
      "  Batch 9,500  of  13,126\n",
      "  Batch 9,600  of  13,126\n",
      "  Batch 9,700  of  13,126\n",
      "  Batch 9,800  of  13,126\n",
      "  Batch 9,900  of  13,126\n",
      "  Batch 10,000  of  13,126\n",
      "  Batch 10,100  of  13,126\n",
      "  Batch 10,200  of  13,126\n",
      "  Batch 10,300  of  13,126\n",
      "  Batch 10,400  of  13,126\n",
      "  Batch 10,500  of  13,126\n",
      "  Batch 10,600  of  13,126\n",
      "  Batch 10,700  of  13,126\n",
      "  Batch 10,800  of  13,126\n",
      "  Batch 10,900  of  13,126\n",
      "  Batch 11,000  of  13,126\n",
      "  Batch 11,100  of  13,126\n",
      "  Batch 11,200  of  13,126\n",
      "  Batch 11,300  of  13,126\n",
      "  Batch 11,400  of  13,126\n",
      "  Batch 11,500  of  13,126\n",
      "  Batch 11,600  of  13,126\n",
      "  Batch 11,700  of  13,126\n",
      "  Batch 11,800  of  13,126\n",
      "  Batch 11,900  of  13,126\n",
      "  Batch 12,000  of  13,126\n",
      "  Batch 12,100  of  13,126\n",
      "  Batch 12,200  of  13,126\n",
      "  Batch 12,300  of  13,126\n",
      "  Batch 12,400  of  13,126\n",
      "  Batch 12,500  of  13,126\n",
      "  Batch 12,600  of  13,126\n",
      "  Batch 12,700  of  13,126\n",
      "  Batch 12,800  of  13,126\n",
      "  Batch 12,900  of  13,126\n",
      "  Batch 13,000  of  13,126\n",
      "  Batch 13,100  of  13,126\n",
      "\n",
      "  Avg loss: 0.53\n",
      "  Accuracy: 0.83\n",
      "  Avg validation Loss: 0.46\n",
      "  Total validation time: 0:01:36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_model(model, optimizer, scheduler, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "execution": {
     "iopub.execute_input": "2023-05-15T11:34:43.326405Z",
     "iopub.status.busy": "2023-05-15T11:34:43.326060Z",
     "iopub.status.idle": "2023-05-15T11:34:43.428961Z",
     "shell.execute_reply": "2023-05-15T11:34:43.428048Z",
     "shell.execute_reply.started": "2023-05-15T11:34:43.326372Z"
    },
    "id": "lkSUl53Ver_Q",
    "outputId": "2915977c-a475-436f-8af6-d0b9d469f742"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>-де</th>\n",
       "      <th>-д^е</th>\n",
       "      <th>target_idx</th>\n",
       "      <th>prediction</th>\n",
       "      <th>is_right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>331232</th>\n",
       "      <td>додумывавшими</td>\n",
       "      <td>дод^умывавшими</td>\n",
       "      <td>3</td>\n",
       "      <td>дод^умывавшими</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647800</th>\n",
       "      <td>маринова</td>\n",
       "      <td>мар^инова</td>\n",
       "      <td>3</td>\n",
       "      <td>мар^инова</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431832</th>\n",
       "      <td>зарядившимся</td>\n",
       "      <td>заряд^ившимся</td>\n",
       "      <td>5</td>\n",
       "      <td>заряд^ившимся</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424960</th>\n",
       "      <td>заполучаем</td>\n",
       "      <td>заполуч^аем</td>\n",
       "      <td>7</td>\n",
       "      <td>заполуч^аем</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1643854</th>\n",
       "      <td>шлихи</td>\n",
       "      <td>шлих^и</td>\n",
       "      <td>4</td>\n",
       "      <td>шл^ихи</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442768</th>\n",
       "      <td>затечешь</td>\n",
       "      <td>затеч^ешь</td>\n",
       "      <td>5</td>\n",
       "      <td>затеч^ешь</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563471</th>\n",
       "      <td>комплементе</td>\n",
       "      <td>комплем^енте</td>\n",
       "      <td>7</td>\n",
       "      <td>комплем^енте</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819140</th>\n",
       "      <td>обмельчавшей</td>\n",
       "      <td>обмельч^авшей</td>\n",
       "      <td>7</td>\n",
       "      <td>обмельч^авшей</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1653022</th>\n",
       "      <td>щурившим</td>\n",
       "      <td>щ^урившим</td>\n",
       "      <td>1</td>\n",
       "      <td>щ^урившим</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1363772</th>\n",
       "      <td>сдружаетесь</td>\n",
       "      <td>сдруж^аетесь</td>\n",
       "      <td>5</td>\n",
       "      <td>сдруж^аетесь</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   -де            -д^е  target_idx      prediction  is_right\n",
       "331232   додумывавшими  дод^умывавшими           3  дод^умывавшими         1\n",
       "647800        маринова       мар^инова           3       мар^инова         1\n",
       "431832    зарядившимся   заряд^ившимся           5   заряд^ившимся         1\n",
       "424960      заполучаем     заполуч^аем           7     заполуч^аем         1\n",
       "1643854          шлихи          шлих^и           4          шл^ихи         0\n",
       "442768        затечешь       затеч^ешь           5       затеч^ешь         1\n",
       "563471     комплементе    комплем^енте           7    комплем^енте         1\n",
       "819140    обмельчавшей   обмельч^авшей           7   обмельч^авшей         1\n",
       "1653022       щурившим       щ^урившим           1       щ^урившим         1\n",
       "1363772    сдружаетесь    сдруж^аетесь           5    сдруж^аетесь         1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wcS_w_3QC50x"
   },
   "source": [
    "### Albert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-05-15T11:34:43.430728Z",
     "iopub.status.busy": "2023-05-15T11:34:43.430398Z",
     "iopub.status.idle": "2023-05-15T11:34:46.112324Z",
     "shell.execute_reply": "2023-05-15T11:34:46.111285Z",
     "shell.execute_reply.started": "2023-05-15T11:34:43.430696Z"
    },
    "id": "FPWwFEIOC4lB",
    "outputId": "bd362b3d-36d5-42d2-e40f-e8d5685bbe1c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33fb5a926e0a4c66a1da755e3c08b45a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/684 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b674be0dea954736ab11eaf6a6bde750",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/47.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at albert-base-v2 were not used when initializing AlbertForSequenceClassification: ['predictions.bias', 'predictions.decoder.weight', 'predictions.LayerNorm.bias', 'predictions.LayerNorm.weight', 'predictions.dense.bias', 'predictions.decoder.bias', 'predictions.dense.weight']\n",
      "- This IS expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"albert-base-v2\", \n",
    "    num_labels = max_len - 1,   \n",
    "    output_attentions = False,\n",
    "    output_hidden_states = False, \n",
    ")\n",
    "\n",
    "model.to(device)\n",
    "optimizer = AdamW(model.parameters(),lr = 2e-5, eps = 1e-8)\n",
    "\n",
    "epochs = 1\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, \n",
    "                                            num_training_steps = total_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-15T11:34:46.114411Z",
     "iopub.status.busy": "2023-05-15T11:34:46.113877Z",
     "iopub.status.idle": "2023-05-15T11:34:46.139948Z",
     "shell.execute_reply": "2023-05-15T11:34:46.138945Z",
     "shell.execute_reply.started": "2023-05-15T11:34:46.114377Z"
    },
    "id": "44HJl-HiIl6_"
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-15T11:34:46.146984Z",
     "iopub.status.busy": "2023-05-15T11:34:46.146064Z",
     "iopub.status.idle": "2023-05-15T12:54:20.740988Z",
     "shell.execute_reply": "2023-05-15T12:54:20.739939Z",
     "shell.execute_reply.started": "2023-05-15T11:34:46.146952Z"
    },
    "id": "xYkIhwDfAu0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   100  of  13,126\n",
      "  Batch   200  of  13,126\n",
      "  Batch   300  of  13,126\n",
      "  Batch   400  of  13,126\n",
      "  Batch   500  of  13,126\n",
      "  Batch   600  of  13,126\n",
      "  Batch   700  of  13,126\n",
      "  Batch   800  of  13,126\n",
      "  Batch   900  of  13,126\n",
      "  Batch 1,000  of  13,126\n",
      "  Batch 1,100  of  13,126\n",
      "  Batch 1,200  of  13,126\n",
      "  Batch 1,300  of  13,126\n",
      "  Batch 1,400  of  13,126\n",
      "  Batch 1,500  of  13,126\n",
      "  Batch 1,600  of  13,126\n",
      "  Batch 1,700  of  13,126\n",
      "  Batch 1,800  of  13,126\n",
      "  Batch 1,900  of  13,126\n",
      "  Batch 2,000  of  13,126\n",
      "  Batch 2,100  of  13,126\n",
      "  Batch 2,200  of  13,126\n",
      "  Batch 2,300  of  13,126\n",
      "  Batch 2,400  of  13,126\n",
      "  Batch 2,500  of  13,126\n",
      "  Batch 2,600  of  13,126\n",
      "  Batch 2,700  of  13,126\n",
      "  Batch 2,800  of  13,126\n",
      "  Batch 2,900  of  13,126\n",
      "  Batch 3,000  of  13,126\n",
      "  Batch 3,100  of  13,126\n",
      "  Batch 3,200  of  13,126\n",
      "  Batch 3,300  of  13,126\n",
      "  Batch 3,400  of  13,126\n",
      "  Batch 3,500  of  13,126\n",
      "  Batch 3,600  of  13,126\n",
      "  Batch 3,700  of  13,126\n",
      "  Batch 3,800  of  13,126\n",
      "  Batch 3,900  of  13,126\n",
      "  Batch 4,000  of  13,126\n",
      "  Batch 4,100  of  13,126\n",
      "  Batch 4,200  of  13,126\n",
      "  Batch 4,300  of  13,126\n",
      "  Batch 4,400  of  13,126\n",
      "  Batch 4,500  of  13,126\n",
      "  Batch 4,600  of  13,126\n",
      "  Batch 4,700  of  13,126\n",
      "  Batch 4,800  of  13,126\n",
      "  Batch 4,900  of  13,126\n",
      "  Batch 5,000  of  13,126\n",
      "  Batch 5,100  of  13,126\n",
      "  Batch 5,200  of  13,126\n",
      "  Batch 5,300  of  13,126\n",
      "  Batch 5,400  of  13,126\n",
      "  Batch 5,500  of  13,126\n",
      "  Batch 5,600  of  13,126\n",
      "  Batch 5,700  of  13,126\n",
      "  Batch 5,800  of  13,126\n",
      "  Batch 5,900  of  13,126\n",
      "  Batch 6,000  of  13,126\n",
      "  Batch 6,100  of  13,126\n",
      "  Batch 6,200  of  13,126\n",
      "  Batch 6,300  of  13,126\n",
      "  Batch 6,400  of  13,126\n",
      "  Batch 6,500  of  13,126\n",
      "  Batch 6,600  of  13,126\n",
      "  Batch 6,700  of  13,126\n",
      "  Batch 6,800  of  13,126\n",
      "  Batch 6,900  of  13,126\n",
      "  Batch 7,000  of  13,126\n",
      "  Batch 7,100  of  13,126\n",
      "  Batch 7,200  of  13,126\n",
      "  Batch 7,300  of  13,126\n",
      "  Batch 7,400  of  13,126\n",
      "  Batch 7,500  of  13,126\n",
      "  Batch 7,600  of  13,126\n",
      "  Batch 7,700  of  13,126\n",
      "  Batch 7,800  of  13,126\n",
      "  Batch 7,900  of  13,126\n",
      "  Batch 8,000  of  13,126\n",
      "  Batch 8,100  of  13,126\n",
      "  Batch 8,200  of  13,126\n",
      "  Batch 8,300  of  13,126\n",
      "  Batch 8,400  of  13,126\n",
      "  Batch 8,500  of  13,126\n",
      "  Batch 8,600  of  13,126\n",
      "  Batch 8,700  of  13,126\n",
      "  Batch 8,800  of  13,126\n",
      "  Batch 8,900  of  13,126\n",
      "  Batch 9,000  of  13,126\n",
      "  Batch 9,100  of  13,126\n",
      "  Batch 9,200  of  13,126\n",
      "  Batch 9,300  of  13,126\n",
      "  Batch 9,400  of  13,126\n",
      "  Batch 9,500  of  13,126\n",
      "  Batch 9,600  of  13,126\n",
      "  Batch 9,700  of  13,126\n",
      "  Batch 9,800  of  13,126\n",
      "  Batch 9,900  of  13,126\n",
      "  Batch 10,000  of  13,126\n",
      "  Batch 10,100  of  13,126\n",
      "  Batch 10,200  of  13,126\n",
      "  Batch 10,300  of  13,126\n",
      "  Batch 10,400  of  13,126\n",
      "  Batch 10,500  of  13,126\n",
      "  Batch 10,600  of  13,126\n",
      "  Batch 10,700  of  13,126\n",
      "  Batch 10,800  of  13,126\n",
      "  Batch 10,900  of  13,126\n",
      "  Batch 11,000  of  13,126\n",
      "  Batch 11,100  of  13,126\n",
      "  Batch 11,200  of  13,126\n",
      "  Batch 11,300  of  13,126\n",
      "  Batch 11,400  of  13,126\n",
      "  Batch 11,500  of  13,126\n",
      "  Batch 11,600  of  13,126\n",
      "  Batch 11,700  of  13,126\n",
      "  Batch 11,800  of  13,126\n",
      "  Batch 11,900  of  13,126\n",
      "  Batch 12,000  of  13,126\n",
      "  Batch 12,100  of  13,126\n",
      "  Batch 12,200  of  13,126\n",
      "  Batch 12,300  of  13,126\n",
      "  Batch 12,400  of  13,126\n",
      "  Batch 12,500  of  13,126\n",
      "  Batch 12,600  of  13,126\n",
      "  Batch 12,700  of  13,126\n",
      "  Batch 12,800  of  13,126\n",
      "  Batch 12,900  of  13,126\n",
      "  Batch 13,000  of  13,126\n",
      "  Batch 13,100  of  13,126\n",
      "\n",
      "  Avg loss: 0.82\n"
     ]
    }
   ],
   "source": [
    "train_model(model, optimizer, scheduler, epochs, val_step=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "execution": {
     "iopub.execute_input": "2023-05-15T12:54:20.744274Z",
     "iopub.status.busy": "2023-05-15T12:54:20.742746Z",
     "iopub.status.idle": "2023-05-15T12:54:20.906158Z",
     "shell.execute_reply": "2023-05-15T12:54:20.905075Z",
     "shell.execute_reply.started": "2023-05-15T12:54:20.744236Z"
    },
    "id": "U7F9cga4HCEd",
    "outputId": "08c14f5d-6016-4e64-a77e-babc9423a02c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>-де</th>\n",
       "      <th>-д^е</th>\n",
       "      <th>target_idx</th>\n",
       "      <th>prediction</th>\n",
       "      <th>is_right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>331232</th>\n",
       "      <td>додумывавшими</td>\n",
       "      <td>дод^умывавшими</td>\n",
       "      <td>3</td>\n",
       "      <td>дод^умывавшими</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647800</th>\n",
       "      <td>маринова</td>\n",
       "      <td>мар^инова</td>\n",
       "      <td>3</td>\n",
       "      <td>мар^инова</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431832</th>\n",
       "      <td>зарядившимся</td>\n",
       "      <td>заряд^ившимся</td>\n",
       "      <td>5</td>\n",
       "      <td>заряд^ившимся</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424960</th>\n",
       "      <td>заполучаем</td>\n",
       "      <td>заполуч^аем</td>\n",
       "      <td>7</td>\n",
       "      <td>заполуч^аем</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1643854</th>\n",
       "      <td>шлихи</td>\n",
       "      <td>шлих^и</td>\n",
       "      <td>4</td>\n",
       "      <td>шл^ихи</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442768</th>\n",
       "      <td>затечешь</td>\n",
       "      <td>затеч^ешь</td>\n",
       "      <td>5</td>\n",
       "      <td>затеч^ешь</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563471</th>\n",
       "      <td>комплементе</td>\n",
       "      <td>комплем^енте</td>\n",
       "      <td>7</td>\n",
       "      <td>комплем^енте</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819140</th>\n",
       "      <td>обмельчавшей</td>\n",
       "      <td>обмельч^авшей</td>\n",
       "      <td>7</td>\n",
       "      <td>обмельч^авшей</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1653022</th>\n",
       "      <td>щурившим</td>\n",
       "      <td>щ^урившим</td>\n",
       "      <td>1</td>\n",
       "      <td>щ^урившим</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1363772</th>\n",
       "      <td>сдружаетесь</td>\n",
       "      <td>сдруж^аетесь</td>\n",
       "      <td>5</td>\n",
       "      <td>сдруж^аетесь</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   -де            -д^е  target_idx      prediction  is_right\n",
       "331232   додумывавшими  дод^умывавшими           3  дод^умывавшими         1\n",
       "647800        маринова       мар^инова           3       мар^инова         1\n",
       "431832    зарядившимся   заряд^ившимся           5   заряд^ившимся         1\n",
       "424960      заполучаем     заполуч^аем           7     заполуч^аем         1\n",
       "1643854          шлихи          шлих^и           4          шл^ихи         0\n",
       "442768        затечешь       затеч^ешь           5       затеч^ешь         1\n",
       "563471     комплементе    комплем^енте           7    комплем^енте         1\n",
       "819140    обмельчавшей   обмельч^авшей           7   обмельч^авшей         1\n",
       "1653022       щурившим       щ^урившим           1       щ^урившим         1\n",
       "1363772    сдружаетесь    сдруж^аетесь           5    сдруж^аетесь         1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QYRVwG3ENt9_"
   },
   "source": [
    "### Deberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-15T12:54:20.908236Z",
     "iopub.status.busy": "2023-05-15T12:54:20.907840Z",
     "iopub.status.idle": "2023-05-15T12:54:38.237039Z",
     "shell.execute_reply": "2023-05-15T12:54:38.235919Z",
     "shell.execute_reply.started": "2023-05-15T12:54:20.908184Z"
    },
    "id": "MEfjrwZZHCCu"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "543d7869929542c7848fa8f41f133a99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/578 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3ec1aaf8d064013b3e67c7488107403",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/286M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-v3-small were not used when initializing DebertaV2ForSequenceClassification: ['mask_predictions.classifier.weight', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.dense.weight', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.bias']\n",
      "- This IS expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['pooler.dense.bias', 'classifier.bias', 'pooler.dense.weight', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"microsoft/deberta-v3-small\", \n",
    "    num_labels = max_len - 1,   \n",
    "    output_attentions = False, \n",
    "    output_hidden_states = False, \n",
    ")\n",
    "\n",
    "model.to(device)\n",
    "optimizer = AdamW(model.parameters(),lr = 2e-5, eps = 1e-8)\n",
    "\n",
    "epochs = 1\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, \n",
    "                                            num_training_steps = total_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-15T12:54:38.239404Z",
     "iopub.status.busy": "2023-05-15T12:54:38.238591Z",
     "iopub.status.idle": "2023-05-15T13:48:40.457042Z",
     "shell.execute_reply": "2023-05-15T13:48:40.455902Z",
     "shell.execute_reply.started": "2023-05-15T12:54:38.239350Z"
    },
    "id": "DoTWbzFIHB_P"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   100  of  13,126\n",
      "  Batch   200  of  13,126\n",
      "  Batch   300  of  13,126\n",
      "  Batch   400  of  13,126\n",
      "  Batch   500  of  13,126\n",
      "  Batch   600  of  13,126\n",
      "  Batch   700  of  13,126\n",
      "  Batch   800  of  13,126\n",
      "  Batch   900  of  13,126\n",
      "  Batch 1,000  of  13,126\n",
      "  Batch 1,100  of  13,126\n",
      "  Batch 1,200  of  13,126\n",
      "  Batch 1,300  of  13,126\n",
      "  Batch 1,400  of  13,126\n",
      "  Batch 1,500  of  13,126\n",
      "  Batch 1,600  of  13,126\n",
      "  Batch 1,700  of  13,126\n",
      "  Batch 1,800  of  13,126\n",
      "  Batch 1,900  of  13,126\n",
      "  Batch 2,000  of  13,126\n",
      "  Batch 2,100  of  13,126\n",
      "  Batch 2,200  of  13,126\n",
      "  Batch 2,300  of  13,126\n",
      "  Batch 2,400  of  13,126\n",
      "  Batch 2,500  of  13,126\n",
      "  Batch 2,600  of  13,126\n",
      "  Batch 2,700  of  13,126\n",
      "  Batch 2,800  of  13,126\n",
      "  Batch 2,900  of  13,126\n",
      "  Batch 3,000  of  13,126\n",
      "  Batch 3,100  of  13,126\n",
      "  Batch 3,200  of  13,126\n",
      "  Batch 3,300  of  13,126\n",
      "  Batch 3,400  of  13,126\n",
      "  Batch 3,500  of  13,126\n",
      "  Batch 3,600  of  13,126\n",
      "  Batch 3,700  of  13,126\n",
      "  Batch 3,800  of  13,126\n",
      "  Batch 3,900  of  13,126\n",
      "  Batch 4,000  of  13,126\n",
      "  Batch 4,100  of  13,126\n",
      "  Batch 4,200  of  13,126\n",
      "  Batch 4,300  of  13,126\n",
      "  Batch 4,400  of  13,126\n",
      "  Batch 4,500  of  13,126\n",
      "  Batch 4,600  of  13,126\n",
      "  Batch 4,700  of  13,126\n",
      "  Batch 4,800  of  13,126\n",
      "  Batch 4,900  of  13,126\n",
      "  Batch 5,000  of  13,126\n",
      "  Batch 5,100  of  13,126\n",
      "  Batch 5,200  of  13,126\n",
      "  Batch 5,300  of  13,126\n",
      "  Batch 5,400  of  13,126\n",
      "  Batch 5,500  of  13,126\n",
      "  Batch 5,600  of  13,126\n",
      "  Batch 5,700  of  13,126\n",
      "  Batch 5,800  of  13,126\n",
      "  Batch 5,900  of  13,126\n",
      "  Batch 6,000  of  13,126\n",
      "  Batch 6,100  of  13,126\n",
      "  Batch 6,200  of  13,126\n",
      "  Batch 6,300  of  13,126\n",
      "  Batch 6,400  of  13,126\n",
      "  Batch 6,500  of  13,126\n",
      "  Batch 6,600  of  13,126\n",
      "  Batch 6,700  of  13,126\n",
      "  Batch 6,800  of  13,126\n",
      "  Batch 6,900  of  13,126\n",
      "  Batch 7,000  of  13,126\n",
      "  Batch 7,100  of  13,126\n",
      "  Batch 7,200  of  13,126\n",
      "  Batch 7,300  of  13,126\n",
      "  Batch 7,400  of  13,126\n",
      "  Batch 7,500  of  13,126\n",
      "  Batch 7,600  of  13,126\n",
      "  Batch 7,700  of  13,126\n",
      "  Batch 7,800  of  13,126\n",
      "  Batch 7,900  of  13,126\n",
      "  Batch 8,000  of  13,126\n",
      "  Batch 8,100  of  13,126\n",
      "  Batch 8,200  of  13,126\n",
      "  Batch 8,300  of  13,126\n",
      "  Batch 8,400  of  13,126\n",
      "  Batch 8,500  of  13,126\n",
      "  Batch 8,600  of  13,126\n",
      "  Batch 8,700  of  13,126\n",
      "  Batch 8,800  of  13,126\n",
      "  Batch 8,900  of  13,126\n",
      "  Batch 9,000  of  13,126\n",
      "  Batch 9,100  of  13,126\n",
      "  Batch 9,200  of  13,126\n",
      "  Batch 9,300  of  13,126\n",
      "  Batch 9,400  of  13,126\n",
      "  Batch 9,500  of  13,126\n",
      "  Batch 9,600  of  13,126\n",
      "  Batch 9,700  of  13,126\n",
      "  Batch 9,800  of  13,126\n",
      "  Batch 9,900  of  13,126\n",
      "  Batch 10,000  of  13,126\n",
      "  Batch 10,100  of  13,126\n",
      "  Batch 10,200  of  13,126\n",
      "  Batch 10,300  of  13,126\n",
      "  Batch 10,400  of  13,126\n",
      "  Batch 10,500  of  13,126\n",
      "  Batch 10,600  of  13,126\n",
      "  Batch 10,700  of  13,126\n",
      "  Batch 10,800  of  13,126\n",
      "  Batch 10,900  of  13,126\n",
      "  Batch 11,000  of  13,126\n",
      "  Batch 11,100  of  13,126\n",
      "  Batch 11,200  of  13,126\n",
      "  Batch 11,300  of  13,126\n",
      "  Batch 11,400  of  13,126\n",
      "  Batch 11,500  of  13,126\n",
      "  Batch 11,600  of  13,126\n",
      "  Batch 11,700  of  13,126\n",
      "  Batch 11,800  of  13,126\n",
      "  Batch 11,900  of  13,126\n",
      "  Batch 12,000  of  13,126\n",
      "  Batch 12,100  of  13,126\n",
      "  Batch 12,200  of  13,126\n",
      "  Batch 12,300  of  13,126\n",
      "  Batch 12,400  of  13,126\n",
      "  Batch 12,500  of  13,126\n",
      "  Batch 12,600  of  13,126\n",
      "  Batch 12,700  of  13,126\n",
      "  Batch 12,800  of  13,126\n",
      "  Batch 12,900  of  13,126\n",
      "  Batch 13,000  of  13,126\n",
      "  Batch 13,100  of  13,126\n",
      "\n",
      "  Avg loss: 0.68\n"
     ]
    }
   ],
   "source": [
    "train_model(model, optimizer, scheduler, epochs, val_step=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-15T13:48:40.459237Z",
     "iopub.status.busy": "2023-05-15T13:48:40.458689Z",
     "iopub.status.idle": "2023-05-15T13:48:40.626921Z",
     "shell.execute_reply": "2023-05-15T13:48:40.625793Z",
     "shell.execute_reply.started": "2023-05-15T13:48:40.459194Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>-де</th>\n",
       "      <th>-д^е</th>\n",
       "      <th>target_idx</th>\n",
       "      <th>prediction</th>\n",
       "      <th>is_right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>331232</th>\n",
       "      <td>додумывавшими</td>\n",
       "      <td>дод^умывавшими</td>\n",
       "      <td>3</td>\n",
       "      <td>дод^умывавшими</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647800</th>\n",
       "      <td>маринова</td>\n",
       "      <td>мар^инова</td>\n",
       "      <td>3</td>\n",
       "      <td>мар^инова</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431832</th>\n",
       "      <td>зарядившимся</td>\n",
       "      <td>заряд^ившимся</td>\n",
       "      <td>5</td>\n",
       "      <td>заряд^ившимся</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424960</th>\n",
       "      <td>заполучаем</td>\n",
       "      <td>заполуч^аем</td>\n",
       "      <td>7</td>\n",
       "      <td>заполуч^аем</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1643854</th>\n",
       "      <td>шлихи</td>\n",
       "      <td>шлих^и</td>\n",
       "      <td>4</td>\n",
       "      <td>шл^ихи</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442768</th>\n",
       "      <td>затечешь</td>\n",
       "      <td>затеч^ешь</td>\n",
       "      <td>5</td>\n",
       "      <td>зат^ечешь</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563471</th>\n",
       "      <td>комплементе</td>\n",
       "      <td>комплем^енте</td>\n",
       "      <td>7</td>\n",
       "      <td>комплем^енте</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819140</th>\n",
       "      <td>обмельчавшей</td>\n",
       "      <td>обмельч^авшей</td>\n",
       "      <td>7</td>\n",
       "      <td>обмельч^авшей</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1653022</th>\n",
       "      <td>щурившим</td>\n",
       "      <td>щ^урившим</td>\n",
       "      <td>1</td>\n",
       "      <td>щур^ившим</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1363772</th>\n",
       "      <td>сдружаетесь</td>\n",
       "      <td>сдруж^аетесь</td>\n",
       "      <td>5</td>\n",
       "      <td>сдруж^аетесь</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   -де            -д^е  target_idx      prediction  is_right\n",
       "331232   додумывавшими  дод^умывавшими           3  дод^умывавшими         1\n",
       "647800        маринова       мар^инова           3       мар^инова         1\n",
       "431832    зарядившимся   заряд^ившимся           5   заряд^ившимся         1\n",
       "424960      заполучаем     заполуч^аем           7     заполуч^аем         1\n",
       "1643854          шлихи          шлих^и           4          шл^ихи         0\n",
       "442768        затечешь       затеч^ешь           5       зат^ечешь         0\n",
       "563471     комплементе    комплем^енте           7    комплем^енте         1\n",
       "819140    обмельчавшей   обмельч^авшей           7   обмельч^авшей         1\n",
       "1653022       щурившим       щ^урившим           1       щур^ившим         0\n",
       "1363772    сдружаетесь    сдруж^аетесь           5    сдруж^аетесь         1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QcKEfNpJHB36"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "08ea5244434a483696ec055f4df09b54": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0b7d09f100dc4e17b217a84bd767c2c1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0d6f28e70b2247eca1ec5cfa2d36bdd7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0ee608c218b649a7916fbee284760539": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_358569e5d3b94e3fb4522a0a35b6084e",
      "placeholder": "​",
      "style": "IPY_MODEL_2cc58540b2754481b3ac83c137c2ba29",
      "value": "Downloading (…)lve/main/config.json: 100%"
     }
    },
    "2cc58540b2754481b3ac83c137c2ba29": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2df73a2904544963a11c1fad9f813740": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a67a910967024ee7a4eca678696b34c5",
      "max": 632,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_43542f8f319c4812b56318ed3e71dbed",
      "value": 632
     }
    },
    "358569e5d3b94e3fb4522a0a35b6084e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3d522b73fae649dab46588e2e764aae4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0b7d09f100dc4e17b217a84bd767c2c1",
      "max": 13126,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0d6f28e70b2247eca1ec5cfa2d36bdd7",
      "value": 13126
     }
    },
    "3e203b1662e64492a2057d4520fa0368": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_407368c5a9a746acad253726bd58809a",
      "placeholder": "​",
      "style": "IPY_MODEL_a31387adc7904ba28185a0fe8c1a78f1",
      "value": "Downloading pytorch_model.bin: 100%"
     }
    },
    "407368c5a9a746acad253726bd58809a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "419b97e53a9842f7ae242e4249dc3797": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0ee608c218b649a7916fbee284760539",
       "IPY_MODEL_2df73a2904544963a11c1fad9f813740",
       "IPY_MODEL_b94c3bfc73564bb98dc424718cec3a58"
      ],
      "layout": "IPY_MODEL_f1a37e256c084e0e80afba84994fd1a7"
     }
    },
    "43542f8f319c4812b56318ed3e71dbed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "76d589e8d6634a7ea67920d26d5bec3e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7e30d332ebaf4ef7a5c425a859680239": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9044e3e2ba7742898681f8c2cab10e1c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e4e3148628544961a843b296135d5fb5",
       "IPY_MODEL_3d522b73fae649dab46588e2e764aae4",
       "IPY_MODEL_c5d4790e629f4709aa45c5158ef3adf4"
      ],
      "layout": "IPY_MODEL_76d589e8d6634a7ea67920d26d5bec3e"
     }
    },
    "950d893c4a4e4311a5b1a20aa05b2b60": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "967cc44586cc4c988237c34ce37cf8c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9d47441331ef4c6a98cbe5e585de060a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a1f4179ff58042e4bed123c98884ac0d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b209c059ebdc4f2495392515d3645f46",
      "placeholder": "​",
      "style": "IPY_MODEL_7e30d332ebaf4ef7a5c425a859680239",
      "value": " 47.7M/47.7M [00:00&lt;00:00, 178MB/s]"
     }
    },
    "a31387adc7904ba28185a0fe8c1a78f1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a67a910967024ee7a4eca678696b34c5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ae85c3386d5d41b1afe0efc511ff94ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_08ea5244434a483696ec055f4df09b54",
      "max": 47679974,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_dc60e7c734c1439caea37c4eaeb81f99",
      "value": 47679974
     }
    },
    "b02cc6c2bb6040d1a1082311917cd293": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b209c059ebdc4f2495392515d3645f46": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b94c3bfc73564bb98dc424718cec3a58": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bd3c10661cfe4253a7df491f05d2335a",
      "placeholder": "​",
      "style": "IPY_MODEL_c7a0e6aa4f9b4f898ea2bfdb581e19b2",
      "value": " 632/632 [00:00&lt;00:00, 34.4kB/s]"
     }
    },
    "bd3c10661cfe4253a7df491f05d2335a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c5d4790e629f4709aa45c5158ef3adf4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d65b8539e6de45d89b308858cf67ec22",
      "placeholder": "​",
      "style": "IPY_MODEL_967cc44586cc4c988237c34ce37cf8c6",
      "value": " 13126/13126 [1:11:38&lt;00:00,  3.46it/s]"
     }
    },
    "c7a0e6aa4f9b4f898ea2bfdb581e19b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d65b8539e6de45d89b308858cf67ec22": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dc60e7c734c1439caea37c4eaeb81f99": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e4e3148628544961a843b296135d5fb5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b02cc6c2bb6040d1a1082311917cd293",
      "placeholder": "​",
      "style": "IPY_MODEL_9d47441331ef4c6a98cbe5e585de060a",
      "value": "100%"
     }
    },
    "efaad66443e642b8a781d2a7bdad8220": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3e203b1662e64492a2057d4520fa0368",
       "IPY_MODEL_ae85c3386d5d41b1afe0efc511ff94ef",
       "IPY_MODEL_a1f4179ff58042e4bed123c98884ac0d"
      ],
      "layout": "IPY_MODEL_950d893c4a4e4311a5b1a20aa05b2b60"
     }
    },
    "f1a37e256c084e0e80afba84994fd1a7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
